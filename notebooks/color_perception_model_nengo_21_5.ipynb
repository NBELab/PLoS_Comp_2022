{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NBELab/PLoS_Comp_2022/blob/main/notebooks/color_perception_model_nengo_21_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oFV_4TlpPcuu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg \n",
        "import scipy\n",
        "import scipy.ndimage\n",
        "import scipy.ndimage.filters\n",
        "\n",
        "import nengo\n",
        "from nengo.dists import Uniform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVtYUEPVPwxF",
        "outputId": "90ff472a-44b2-4bcb-ba7e-7ba60c87d718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nengo in /usr/local/lib/python3.7/dist-packages (3.2.0)\n",
            "Requirement already satisfied: nengo-ocl in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from nengo) (1.21.6)\n",
            "Requirement already satisfied: pyopencl in /usr/local/lib/python3.7/dist-packages (from nengo-ocl) (2022.1.6)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.7/dist-packages (from nengo-ocl) (1.2.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from mako->nengo-ocl) (4.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->nengo-ocl) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->mako->nengo-ocl) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->mako->nengo-ocl) (3.8.1)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pyopencl->nengo-ocl) (2.5.2)\n",
            "Requirement already satisfied: pytools>=2021.2.7 in /usr/local/lib/python3.7/dist-packages (from pyopencl->nengo-ocl) (2022.1.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install nengo nengo-ocl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert RGB image to gray level\n",
        "def rgb2gray(rgb):\n",
        "\n",
        "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
        "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
        "\n",
        "    return gray\n",
        "   \n",
        "#convert RGB image to opponent channels\n",
        "def rgb2opp(rgb):\n",
        "  R, G, B = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
        "  O3 = rgb2gray(rgb)\n",
        "  O1 = (R-G)/np.sqrt(2)\n",
        "  O2 = (R + G - 2*B)/np.sqrt(6)\n",
        "  return np.stack((O1,O2,O3),axis =-1)\n",
        "\n",
        "#convert opponet channels back to RGB image  \n",
        "def opp2rgb(opp):\n",
        "  a = 0.2989;\n",
        "  b = 0.587;\n",
        "  c = 0.114;\n",
        "\n",
        "  O1, O2, O3 = opp[:,:,0], opp[:,:,1], opp[:,:,2]\n",
        "\n",
        "  B = (O3-np.sqrt(2)/2*(a-b)*O1 - np.sqrt(6)/2*(a+b)*O2) / (a+b+c);\n",
        "  G = (np.sqrt(6)*O2-np.sqrt(2)*O1+2*B)/2;\n",
        "  R = np.sqrt(2)*O1+G;\n",
        "\n",
        "  return np.stack((R,G,B),axis =-1)\n",
        "\n",
        "# spatial gaussian filter\n",
        "def fspecial_gauss(size, sigma):\n",
        "\n",
        "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
        "    \"\"\"\n",
        "\n",
        "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
        "    g = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
        "    return g/g.sum()"
      ],
      "metadata": {
        "id": "osxk-xCEm43e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E4oXsuOtd0b5"
      },
      "outputs": [],
      "source": [
        "\n",
        "kernel = fspecial_gauss(21,5)\n",
        "h = 90\n",
        "w = 120\n",
        "\n",
        "# 2d convulotion layer \n",
        "def conv_filter2d(kernel,n_neurons_ens =2):\n",
        "    filter = kernel[:,:,None,None] \n",
        "    conv = nengo.Convolution(n_filters =1, input_shape=(h,w,1), kernel_size=tuple([kernel.shape[0],kernel.shape[1]]),  strides=tuple([1,1]),  padding='same', channels_last=True,init= filter)\n",
        "\n",
        "    if(n_neurons_ens == 2):\n",
        "    \n",
        "      layer = nengo.networks.EnsembleArray(n_neurons_ens, conv.output_shape.size,                                         \n",
        "                                          intercepts=Uniform(0, 0),\n",
        "                                          max_rates=Uniform(200, 200),\n",
        "                                          encoders=[[1],[-1]],\n",
        "                                          neuron_type= nengo.SpikingRectifiedLinear()\n",
        "                                          )\n",
        "    else:\n",
        "      layer = nengo.networks.EnsembleArray(n_neurons_ens, conv.output_shape.size,                                         \n",
        "                                          intercepts=Uniform(0, 0),\n",
        "                                          max_rates=Uniform(100, 200),                                          \n",
        "                                          neuron_type= nengo.SpikingRectifiedLinear()\n",
        "                                          )\n",
        "\n",
        "                      \n",
        "    return layer,conv\n",
        "\n",
        "# single opponent pathway, each opponent input is convolved with spatial gaussian filter (definded by kernel)\n",
        "def color_network():\n",
        "  with nengo.Network() as net:\n",
        "\n",
        "    o1_ens = nengo.networks.EnsembleArray(\n",
        "        2,\n",
        "        h*w,         \n",
        "        intercepts=Uniform(0, 0),       \n",
        "        max_rates=Uniform(200, 200),       \n",
        "        encoders=[[1],[-1]],\n",
        "        neuron_type=nengo.SpikingRectifiedLinear()\n",
        "    )\n",
        "    o2_ens = nengo.networks.EnsembleArray(\n",
        "        2,\n",
        "        h*w,         \n",
        "        intercepts=Uniform(0, 0),       \n",
        "        max_rates=Uniform(200, 200),       \n",
        "        encoders=[[1],[-1]],\n",
        "        neuron_type=nengo.SpikingRectifiedLinear()\n",
        "    )    \n",
        "    o3_ens = nengo.networks.EnsembleArray(\n",
        "        2,\n",
        "        h*w,         \n",
        "        intercepts=Uniform(0, 0),       \n",
        "        max_rates=Uniform(200, 200),       \n",
        "        encoders=[[1],[-1]],\n",
        "        neuron_type=nengo.SpikingRectifiedLinear()\n",
        "    )\n",
        "    net.diff1,conv = conv_filter2d(kernel)\n",
        "    net.diff2,conv = conv_filter2d(kernel)\n",
        "    net.diff3,conv = conv_filter2d(kernel)\n",
        "    net.O1 = nengo.Node(size_in=n)\n",
        "    net.O2 = nengo.Node(size_in=n)\n",
        "    net.O3 = nengo.Node(size_in=n)\n",
        "   \n",
        "\n",
        "    nengo.Connection(net.O1, o1_ens.input,synapse=None)\n",
        "    nengo.Connection(net.O2, o2_ens.input,synapse=None)\n",
        "    nengo.Connection(net.O3, o3_ens.input,synapse=None)\n",
        "   \n",
        "\n",
        "    nengo.Connection(o1_ens.output, net.diff1.input,transform=conv,synapse=None)\n",
        "    nengo.Connection(o2_ens.output, net.diff2.input,transform=conv,synapse=None)\n",
        "    nengo.Connection(o3_ens.output, net.diff3.input,transform=conv,synapse=None)\n",
        "\n",
        "\n",
        "  return net\n",
        "\n",
        "# LaplaceNet recurcivlly reconstucts image - double opponent pathway\n",
        "def LaplaceNet(number_neurons=2):\n",
        "  \n",
        "  tau = 1/4\n",
        "  \n",
        "  w_filter = tau* np.array([[0, 1, 0], [1, -4, 1],[0, 1, 0]])\n",
        "  \n",
        "  n = 90*120\n",
        "  \n",
        " \n",
        "  with nengo.Network() as laplaceSolver:\n",
        "\n",
        "    laplaceSolver.input =  nengo.Node(size_in=n)\n",
        "  \n",
        "    layer_on,conv_on = conv_filter2d(w_filter,number_neurons)\n",
        "  \n",
        "    nengo.Connection(laplaceSolver.input, layer_on.input,transform=tau)   \n",
        "    nengo.Connection(layer_on.output, layer_on.input,transform=conv_on)\n",
        "    nengo.Connection(layer_on.output, layer_on.input,transform=1)\n",
        "    laplaceSolver.output = nengo.Node(size_in=n ,size_out=n )\n",
        "    nengo.Connection(layer_on.output, laplaceSolver.output)\n",
        "    \n",
        "\n",
        "        \n",
        "  return laplaceSolver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DAgLGM-1R942"
      },
      "outputs": [],
      "source": [
        "#input images\n",
        "y = np.zeros((19,90,120,3))\n",
        "image = mpimg.imread('/content/images/the_shoe_resized.png')\n",
        "img = image[:,:,0:3]\n",
        "y[0,:,:,:] = img\n",
        "\n",
        "image = mpimg.imread('/content/images/the_dress_resized.png')\n",
        "img = image[:,:,0:3]\n",
        "y[1,:,:,:] = img\n",
        "\n",
        "\n",
        "#colored face\n",
        "image = mpimg.imread('/content/images/Image_by_Alexander_Ivanov_from_pixabay_ar_s.jpg')\n",
        "img = image[:,:,0:3]/255\n",
        "y[2,:,:,:] = img\n",
        "\n",
        "#louvre\n",
        "image = mpimg.imread('/content/images/Edi_Nugraha_s.jpg')\n",
        "img = image[:,:,0:3]/np.max(image)\n",
        "y[3,:,:,:] = img\n",
        "\n",
        "#bulding\n",
        "image = mpimg.imread('/content/images/Michael_Gaida_s.jpg')\n",
        "img = image[:,:,0:3]/np.max(image)\n",
        "y[4,:,:,:] = img\n",
        "\n",
        "#german-museum\n",
        "image = mpimg.imread('/content/images/german-museum-by-Alexander-Ivanov_s.jpg')\n",
        "img = image[:,:,0:3]/np.max(image)\n",
        "y[5,:,:,:] = img\n",
        "\n",
        "#red squere\n",
        "image = mpimg.imread('/content/images/red.png')\n",
        "img = image[:,:,0:3]/np.max(image)\n",
        "y[6,:,:,:] = img\n",
        "\n",
        "\n",
        "image = mpimg.imread('/content/images/cubeillusion_s.png')\n",
        "img = image[:,:,0:3]/np.max(image)\n",
        "y[7,:,:,:] = img\n",
        "\n",
        "\n",
        "image = mpimg.imread('/content/images/blue_cube_s.png')\n",
        "img = image[:,:,0:3]/np.max(image)\n",
        "y[8,:,:,:] = img\n",
        "\n",
        "\n",
        "\n",
        "image = mpimg.imread('/content/images/yellow_cube_s.png')\n",
        "img = image[:,:,0:3]/np.max(image)\n",
        "y[9,:,:,:] = img\n",
        "\n",
        "\n",
        "image = mpimg.imread('/content/images/colored_face_grid_s.png')\n",
        "img = image[:,:,0:3]/np.max(image)\n",
        "y[10,:,:,:] = img\n",
        "\n",
        "\n",
        "\n",
        "image = mpimg.imread('/content/images/red_grid_s.png')\n",
        "img = image[:,:,0:3]/np.max(image)\n",
        "y[11,:,:,:] = img\n",
        "\n",
        "\n",
        "image = mpimg.imread('/content/images/red_grid_s_sat_4_size_50px.png')\n",
        "img = image[:,:,0:3]/np.max(image)\n",
        "y[12,:,:,:] = img\n",
        "\n",
        "\n",
        "image = mpimg.imread('/content/images/colored_face_grid_s_sat_4_size50px.png')\n",
        "img = image[:,:,0:3]/np.max(image)\n",
        "y[13,:,:,:] = img\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seR7LvZmvgOX",
        "outputId": "b32938dc-063f-4987-f304-2bab504df107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19, 90, 120, 4)\n",
            "(19, 1, 10800)\n",
            "(19, 1, 10800)\n",
            "(19, 1, 10800)\n",
            "(19, 1, 10800)\n",
            "(19, 1, 10800)\n",
            "(19, 1, 10800)\n"
          ]
        }
      ],
      "source": [
        "def convert2opp_laplace(y):\n",
        "  H = y.shape[1]\n",
        "  W = y.shape[2]\n",
        "  opp_images_lap = np.zeros((y.shape[0],y.shape[1],y.shape[2],4))\n",
        "  \n",
        "  j = np.arange(1,H-1,1) \n",
        "  k = np.arange(1,W-1,1)\n",
        "  for i in range(y.shape[0]): \n",
        "    img_opp = rgb2opp(1*y[i])\n",
        "    \n",
        "    for c in range(3): \n",
        "      opp_images_lap[i,:,:,c] = -1*scipy.ndimage.filters.laplace(img_opp[:,:,c],mode = 'nearest')      \n",
        "     \n",
        "  return opp_images_lap\n",
        "\n",
        "def sample_color(y,s):\n",
        "  img_opp_s = np.zeros_like(y)\n",
        "  for i in range(y.shape[0]):\n",
        "    img_opp = rgb2opp(1*y[i])    \n",
        "    \n",
        "    img_opp_s[i,::s,::s,:] = img_opp[::s,::s,:]\n",
        "    img_opp_s[i,::s,::s,2] = img_opp[:,:,2]\n",
        "  return img_opp_s[:,:,:,0],img_opp_s[:,:,:,1],img_opp_s[:,:,:,2]\n",
        "\n",
        "#prepare the inputs, and convert to 1D vector\n",
        "\n",
        "# DO pathway \n",
        "opp_images = convert2opp_laplace(y)\n",
        "print(opp_images.shape)\n",
        "RG_DO = 10*np.reshape(opp_images[:,:,:,0],(opp_images[:,:,:,0].shape[0],1, -1))\n",
        "BY_DO = 10*np.reshape(opp_images[:,:,:,1],(opp_images[:,:,:,1].shape[0],1, -1))\n",
        "gray_on_off =10*np.reshape(opp_images[:,:,:,2],(opp_images[:,:,:,2].shape[0],1, -1))\n",
        "\n",
        "print(RG_DO.shape)\n",
        "print(BY_DO.shape)\n",
        "print(gray_on_off.shape)\n",
        "\n",
        "\n",
        "# SO pathway\n",
        "RG,BY,Gray = sample_color(y,1)\n",
        "\n",
        "RG = 10*np.reshape(RG,(RG.shape[0],1, -1))\n",
        "BY = 10*np.reshape(BY,(BY.shape[0],1, -1))\n",
        "Gray = 10*np.reshape(Gray,(Gray.shape[0],1, -1))\n",
        "print(RG.shape)\n",
        "print(BY.shape)\n",
        "print(Gray.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En2T2u_7xIgE",
        "outputId": "8a9cbfa4-91c4-4ad0-a7ea-aa14c34c1a14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nengo/node.py:63: UserWarning: 'Node.size_out' is being overwritten with 'Node.size_in' since 'Node.output=None'\n",
            "  \"'Node.size_out' is being overwritten with \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "777600\n"
          ]
        }
      ],
      "source": [
        "\n",
        "present_time = 0.3\n",
        "n = h*w\n",
        "\n",
        "net = nengo.Network(label=\"NetColor\")\n",
        "with net:\n",
        "  gray_input_l = nengo.Node(nengo.processes.PresentInput(\n",
        "      Gray, presentation_time=present_time\n",
        "  ))\n",
        "  gray_input_on_off = nengo.Node(nengo.processes.PresentInput(\n",
        "      gray_on_off, presentation_time=present_time\n",
        "  ))\n",
        "  RG_input = nengo.Node(nengo.processes.PresentInput(\n",
        "      RG_DO, presentation_time=present_time\n",
        "  ))\n",
        "\n",
        "  BY_input = nengo.Node(nengo.processes.PresentInput(\n",
        "      BY_DO, presentation_time=present_time\n",
        "  ))\n",
        "\n",
        "  RG_input_so = nengo.Node(nengo.processes.PresentInput(\n",
        "      RG, presentation_time=present_time\n",
        "  ))\n",
        "\n",
        "  BY_input_so = nengo.Node(nengo.processes.PresentInput(\n",
        "      BY, presentation_time=present_time\n",
        "  ))\n",
        "  \n",
        "  \n",
        "  gray_filling_in = LaplaceNet(20)\n",
        "  RG_filling_in   = LaplaceNet(20)\n",
        "  BY_filling_in   = LaplaceNet(20)\n",
        "  \n",
        "  nengo.Connection(gray_input_on_off,gray_filling_in.input)\n",
        "  nengo.Connection(RG_input, RG_filling_in.input)\n",
        "  nengo.Connection(BY_input, BY_filling_in.input)\n",
        "\n",
        "  color_filling_in_so = color_network()\n",
        "  nengo.Connection(RG_input_so, color_filling_in_so.O1)\n",
        "  nengo.Connection(BY_input_so, color_filling_in_so.O2)\n",
        "  nengo.Connection(gray_input_l, color_filling_in_so.O3)\n",
        "  \n",
        "\n",
        " \n",
        "  gray_do_out = nengo.Probe(gray_filling_in.output,synapse=0.05)\n",
        "  RG_do_out = nengo.Probe(RG_filling_in.output,synapse=0.05)\n",
        "  BY_do_out = nengo.Probe(BY_filling_in.output,synapse=0.05)\n",
        "  RG_so_out = nengo.Probe(color_filling_in_so.diff1.output, synapse=0.05)\n",
        "  BY_so_out = nengo.Probe(color_filling_in_so.diff2.output, synapse=0.05)\n",
        "  gray_so_out = nengo.Probe(color_filling_in_so.diff3.output, synapse=0.05)\n",
        "print(net.n_neurons)    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "1N17JpfBJDRi",
        "outputId": "305e128d-4b57-4849-bfde-ac3de770992b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No context argument was provided to nengo_ocl.Simulator\n",
            "Calling pyopencl.create_some_context() for you now:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nengo_ocl/simulator.py:205: UserWarning: This version of `nengo_ocl` has not been tested with your `nengo` version (3.2.0). The latest fully supported version is 3.1.0\n",
            "  \"supported version is %s\" % (nengo.__version__, latest_nengo_version)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vdom.v1+json": {
              "tagName": "div",
              "attributes": {}
            },
            "text/html": [
              "\n",
              "                <script>\n",
              "                    if (Jupyter.version.split(\".\")[0] < 5) {\n",
              "                        var pb = document.getElementById(\"120da204-064c-46a4-823d-4d9211f09bb4\");\n",
              "                        var text = document.createTextNode(\n",
              "                            \"HMTL progress bar requires Jupyter Notebook >= \" +\n",
              "                            \"5.0 or Jupyter Lab. Alternatively, you can use \" +\n",
              "                            \"TerminalProgressBar().\");\n",
              "                        pb.parentNode.insertBefore(text, pb);\n",
              "                    }\n",
              "                </script>\n",
              "                <div id=\"120da204-064c-46a4-823d-4d9211f09bb4\" style=\"\n",
              "                    width: 100%;\n",
              "                    border: 1px solid #cfcfcf;\n",
              "                    border-radius: 4px;\n",
              "                    text-align: center;\n",
              "                    position: relative;\">\n",
              "                  <div class=\"pb-text\" style=\"\n",
              "                      position: absolute;\n",
              "                      width: 100%;\">\n",
              "                    0%\n",
              "                  </div>\n",
              "                  <div class=\"pb-fill\" style=\"\n",
              "                      background-color: #bdd2e6;\n",
              "                      width: 0%;\">\n",
              "                    <style type=\"text/css\" scoped=\"scoped\">\n",
              "                        @keyframes pb-fill-anim {\n",
              "                            0% { background-position: 0 0; }\n",
              "                            100% { background-position: 100px 0; }\n",
              "                        }\n",
              "                    </style>\n",
              "                    &nbsp;\n",
              "                  </div>\n",
              "                </div>"
            ],
            "text/plain": [
              "HtmlProgressBar cannot be displayed. Please use the TerminalProgressBar. It can be enabled with `nengo.rc['progress']['progress_bar'] = 'nengo.utils.progress.TerminalProgressBar'`."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vdom.v1+json": {
              "tagName": "div",
              "attributes": {
                "id": "65d58d98-7b99-4eb3-9aa4-e567203900a3",
                "style": {
                  "width": "100%",
                  "boxSizing": "border-box",
                  "border": "1px solid #cfcfcf",
                  "borderRadius": "4px",
                  "textAlign": "center",
                  "position": "relative"
                }
              },
              "children": [
                {
                  "tagName": "div",
                  "attributes": {
                    "class": "pb-text",
                    "style": {
                      "position": "absolute",
                      "width": "100%"
                    }
                  },
                  "children": [
                    "Simulation finished in 0:00:19."
                  ]
                },
                {
                  "tagName": "div",
                  "attributes": {
                    "class": "pb-fill",
                    "style": {
                      "width": "100%",
                      "animation": "none",
                      "backgroundColor": "#bdd2e6",
                      "backgroundImage": "none",
                      "transition": "width 0.1s linear"
                    }
                  },
                  "children": [
                    {
                      "tagName": "style",
                      "attributes": {
                        "type": "text/css",
                        "scoped": "scoped"
                      },
                      "children": [
                        "\n                        @keyframes pb-fill-anim {\n                            0% { background-position: 0 0; }\n                            100% { background-position: 100px 0; }\n                        }}"
                      ]
                    },
                    " "
                  ]
                }
              ]
            },
            "text/html": [
              "<script>\n",
              "              (function () {\n",
              "                  var root = document.getElementById('120da204-064c-46a4-823d-4d9211f09bb4');\n",
              "                  var text = root.getElementsByClassName('pb-text')[0];\n",
              "                  var fill = root.getElementsByClassName('pb-fill')[0];\n",
              "\n",
              "                  text.innerHTML = 'Simulation finished in 0:00:19.';\n",
              "                  \n",
              "            if (100.0 > 0.) {\n",
              "                fill.style.transition = 'width 0.1s linear';\n",
              "            } else {\n",
              "                fill.style.transition = 'none';\n",
              "            }\n",
              "\n",
              "            fill.style.width = '100.0%';\n",
              "            fill.style.animation = 'none';\n",
              "            fill.style.backgroundImage = 'none'\n",
              "        \n",
              "                  \n",
              "                fill.style.animation = 'none';\n",
              "                fill.style.backgroundImage = 'none';\n",
              "            \n",
              "              })();\n",
              "        </script>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import nengo_ocl\n",
        "runtime = 14 * present_time\n",
        "with nengo_ocl.Simulator(net) as sim:\n",
        "#with nengo.Simulator(nengo_converter.net) as sim:\n",
        "    sim.run(runtime)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io import savemat\n",
        "Z = np.zeros((18,90,120,6))\n",
        "for i in range(13):\n",
        "  m = int((i)*(present_time*1000)+((present_time*1000)-1))\n",
        "  gray_hp = np.reshape(sim.data[gray_do_out][m],(h,w))\n",
        "  gray_lp = np.reshape(sim.data[gray_so_out][m],(h,w))\n",
        "  o1_hp = np.reshape(sim.data[RG_do_out][m],(h,w))\n",
        "  o2_hp = np.reshape(sim.data[BY_do_out][m],(h,w))\n",
        "  o1_lp = np.reshape(sim.data[RG_so_out][m],(h,w))\n",
        "  o2_lp = np.reshape(sim.data[BY_so_out][m],(h,w))\n",
        "  Z[i,:,:,0] = gray_hp\n",
        "  Z[i,:,:,1] = gray_lp\n",
        "  Z[i,:,:,2] = o1_hp\n",
        "  Z[i,:,:,3] = o2_hp\n",
        "  Z[i,:,:,4] = o1_lp\n",
        "  Z[i,:,:,5] = o2_lp\n",
        "\n",
        "np.save('color_output', Z)\n",
        "temp = np.load('color_output.npy')\n",
        "savemat('lp_color_output.mat', {\"color_output\":temp})"
      ],
      "metadata": {
        "id": "HEr3ekiROf02"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NT_SCB9EkJ7M"
      },
      "outputs": [],
      "source": [
        "# save and display results\n",
        "os.makedirs('results',exist_ok=True)\n",
        "\n",
        "for i in range(13):\n",
        "  m = int((i)*(present_time*1000)+((present_time*1000)-1))\n",
        "  plt.figure()\n",
        "  plt.imshow(y[m//int(present_time*1000),:,:,:])\n",
        "  plt.title('Original image')\n",
        "  for alpha_i in [1,0.5]:    \n",
        "    beta_i = 1- alpha_i\n",
        "    os.makedirs('results/'+str(alpha_i),exist_ok=True)\n",
        "    for alpha_c in [1,0.7,0.5,0]:    \n",
        "      beta_c = 1- alpha_c    \n",
        "      \n",
        "      I = alpha_i*(np.reshape(sim.data[gray_do_out][m],(h,w))) + beta_i*np.reshape(sim.data[gray_so_out][m],(h,w))\n",
        "      I = I-np.min(I) \n",
        "      gray = 500*I/np.max(I)\n",
        "  \n",
        "      o1 = 100*(beta_c*sim.data[RG_so_out][m]+alpha_c*sim.data[RG_do_out][m])\n",
        "      o2 = 100*(beta_c*sim.data[BY_so_out][m]+alpha_c*sim.data[BY_do_out][m])\n",
        "      \n",
        "      out_img = np.stack((np.reshape(o1,(h,w)),np.reshape(o2,(h,w)),gray),axis=-1)\n",
        "      plt.figure()\n",
        "      plt.imshow(opp2rgb(out_img)/500)\n",
        "      plt.title('Predicted image '+'alpha_i: '+str(alpha_i)+' alpha_c: '+str(alpha_c))\n",
        "      \n",
        "      im = np.maximum(opp2rgb(out_img)/500,0)\n",
        "      im = np.minimum(im,1)\n",
        "      matplotlib.image.imsave('/content/results/' + str(alpha_i)+'/intesity_alpaha_'+str(alpha_i)+ '_color_alpha_'+str(alpha_c) +'_image_' + str(i) +'.png', im)\n",
        "\n",
        "\n",
        "  \n",
        "  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "color_perception_model_nengo_21_5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}